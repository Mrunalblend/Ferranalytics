# -*- coding: utf-8 -*-
"""Ferranalytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K7Lz-WQyopuEBAATpxKungeukmeHyZDB
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

df = pd.read_csv("/content/train.csv")
df.head()

df.drop(['date'], axis=1, inplace=True)
df1 = df.replace(',', '.', regex=True)
df1.head()

df2 = df1.astype(float)
df2.dtypes

from sklearn.model_selection import train_test_split

X = df2.drop(['% Silica Concentrate'], axis=1)
y = df2['% Silica Concentrate']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

import numpy as np
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error

model_ann = keras.Sequential([
        keras.layers.Dense(22, input_shape=(22,), activation='relu'),  # Input layer with 22 features
        keras.layers.Dense(14, activation='relu'),  # Hidden layer
        keras.layers.Dense(1, activation='linear')  # Output layer (linear for regression)
])

model_ann.compile(optimizer='adam',
                  loss='mean_squared_error',  # Loss should be suitable for regression, e.g., 'mean_squared_error' or 'mean_absolute_error'
                  metrics=['mae'])  # Using Mean Absolute Error (MAE) as the default metric

model_ann.fit(X, y, epochs=25)

# Evaluate the model on the test set
# print("\nModel evaluation on test data:")
# model.evaluate(X_test, y_test)

# Make predictions on the test set
# y_preds_ann = model_ann.predict(X_test)

df_test = pd.read_csv("/content/test.csv")
df_test.head()

df_test.drop(['date'], axis=1, inplace=True)
df1_test = df_test.replace(',', '.', regex=True)
df1_test.head()

df2_test = df1_test.astype(float)
df2_test.dtypes

y_preds_ann = model_ann.predict(df2_test)
y_preds_ann

# import numpy as np

# # First prediction


# # Second prediction
# y_preds_ann_2 = model_ann.predict(df_test)

# # Average the two predictions
# y_preds_avg = np.mean([y_preds_ann, y_preds_ann_2], axis=0)

# # Convert the average predictions to a DataFrame
# df_preds_avg = pd.DataFrame(y_preds_avg, columns=['% Silica Concentrate'])

# # Save the averaged predictions to a CSV file
# df_preds_avg.to_csv('averaged_predictions_silica_concentrate.csv', index=False)

# # Now, you have saved the averaged predictions to a CSV file.

df_preds= pd.DataFrame(y_preds_ann, columns=['% Silica Concentrate'])


# Assuming you have a DataFrame called df
num_rows = df_preds.shape[0]  # This returns the number of rows

print(f"Number of rows: {num_rows}")

df_preds.index = df_preds.index + 1  # Start index from 1
df_preds.index.name = 'ID'  # Name the index column 'id'

# Save the DataFrame to a CSV file
df_preds.to_csv('answer2.csv', index=True)

# Import necessary libraries
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

# Assuming you have your train and test sets: X_train, X_test, y_train, y_test
# Here is an example structure:
# X_train and X_test are the feature matrices (input variables)
# y_train and y_test are the target (output) variables

# Initialize the DecisionTreeRegressor
model_dtr = DecisionTreeRegressor(random_state=42)  # Random state for reproducibility

# Train the model
model_dtr.fit(X, y)

# # Make predictions on the test set
# y_preds = model_dtr.predict(X_test)

# # Evaluate the model
# mse = mean_squared_error(y_test, y_preds)
# r2 = r2_score(y_test, y_preds)

# # Print the evaluation results
# print(f"Mean Squared Error (MSE): {mse}")
# print(f"RÂ² Score (Accuracy in Regression): {r2}")

# # Optionally, you can make predictions on new unseen data using model_dtr.predict(new_data)

y_preds_dtr = model_dtr.predict(df2_test)
y_preds_dtr

df_preds_dtr= pd.DataFrame(y_preds_dtr, columns=['% Silica Concentrate'])


# Assuming you have a DataFrame called df
num_rows = df_preds_dtr.shape[0]  # This returns the number of rows

print(f"Number of rows: {num_rows}")

df_preds_dtr.index = df_preds_dtr.index + 1  # Start index from 1
df_preds_dtr.index.name = 'ID'  # Name the index column 'id'

# Save the DataFrame to a CSV file
df_preds_dtr.to_csv('answer3_updated.csv', index=True)

